{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x114b50340> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x114b52c50> root_client=<openai.OpenAI object at 0x1072e7a00> root_async_client=<openai.AsyncOpenAI object at 0x114b503d0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence techniques that are designed to generate new content that is similar to existing data. Unlike traditional AI, which focuses on classifying or predicting based on input data, generative AI creates new data instances. \\n\\nKey technologies behind generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates new data instances, while the discriminator evaluates them against real data, effectively encouraging the generator to improve over time.\\n\\n2. **Variational Autoencoders (VAEs):** These are a type of autoencoder that learns to generate new data by encoding input data into a lower-dimensional space and then reconstructing it. VAEs are particularly useful for generating variations of data that are structurally similar.\\n\\n3. **Transformer Models:** These models, like GPT (Generative Pre-trained Transformer), are particularly prominent in natural language processing tasks. They leverage attention mechanisms to generate text that is coherent and contextually relevant.\\n\\n4. **Diffusion Models:** These probabilistic models generate new data by iteratively refining sampled noisy data until it resembles the training data. They have gained popularity for their ability to generate high-quality images.\\n\\nApplications of generative AI are extensive, encompassing fields such as art, music, text, and even video generation. It allows for creative processes such as generating artwork or music, creating realistic human-like images, developing language models for text synthesis, simulating environments, and more. Generative AI has vast potential in industries like entertainment, design, education, and beyond, offering new ways to innovate and automate content creation.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 13, 'total_tokens': 352, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa860cbac8', 'id': 'chatcmpl-BM4JaAN6b9AwVLL0nzWZeLqmcid7c', 'finish_reason': 'stop', 'logprobs': None} id='run-70352c64-d317-4f8c-bfb9-ec29183baa17-0' usage_metadata={'input_tokens': 13, 'output_tokens': 339, 'total_tokens': 352, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is an advanced set of tools and services designed by Langchain to enhance the development, testing, and evaluation of applications that use large language models (LLMs). Released in mid-2023, Langsmith offers developers a range of features to streamline their workflows and improve the reliability and performance of their LLM applications. \\n\\nKey features of Langsmith include:\\n\\n1. **Langchain Client**: This is a comprehensive platform for tracking and managing datasets and chains, providing invaluable insights into the functioning and behavior of LLM models in production.\\n\\n2. **Dataset Management**: Langsmith offers robust dataset management tools that allow developers to manage and utilize various datasets effectively, ensuring that models are trained and fine-tuned with relevant and high-quality data.\\n\\n3. **Integration with Langchain**: Langsmith seamlessly integrates with Langchain, allowing developers to take advantage of the broader Langchain ecosystem, including access to various machine learning tools and libraries.\\n\\n4. **Application Performance Metrics**: Developers can use Langsmith to monitor key performance metrics and diagnose issues with their applications, increasing reliability and facilitating faster resolution of problems.\\n\\n5. **Testing and Evaluation**: Langsmith allows developers to systematically test their applications, facilitating more structured and efficient evaluation processes to ensure the desired performance outcomes.\\n\\nOverall, Langsmith acts as an enabler and accelerator for developers working with LLMs, helping to advance the automation of machine learning workflows and support more robust and effective application development.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 33, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BM4JpXxpAet7ceZwLY47r8qsvkrLT', 'finish_reason': 'stop', 'logprobs': None} id='run-78fa766f-fdce-48fc-bbee-a491d6190d64-0' usage_metadata={'input_tokens': 33, 'output_tokens': 293, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Langsmith is a comprehensive platform developed by LangChain aimed at facilitating the development, debugging, and monitoring of applications powered by large language models (LLMs). This toolkit is designed to help developers meticulously manage interactions with LLMs, offering features for tracking and optimizing these interactions to improve performance and reliability. It provides capabilities such as logging, tracing, evaluating, and visualizing prompt chains. These functionalities are essential for developers to understand how their models and applications are behaving and where improvements can be made. Additionally, Langsmith's focus on optimization helps in making the applications more efficient, ensuring they deliver relevant and accurate outputs in various tasks.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
